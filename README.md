## Collections of Paper Focused on LMM4Vision or ViTs.

Welcome to open issues or pull requests (recommended)

### Awesome-LMM4Vision

- [SPAE]Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs
  - model non-linguistic modality as a language sequence that LLMs can comprehend
  - In contrast to the majority of VQ-VAE approaches, SPAE maps to an interpretable **discrete latent space**, i.e., words.
  - Dilation subsampler selects the positions for quantization

### Awesome-Vision-Transformers

#### CVPR 2023

- [Castiling-ViT]Compressing Self-Attention via Switching Towards Linear-Angular Attention at Vision Transformer Inference[[paper](https://openaccess.thecvf.com/content/CVPR2023/papers/You_Castling-ViT_Compressing_Self-Attention_via_Switching_Towards_Linear-Angular_Attention_at_Vision_CVPR_2023_paper.pdf), [project](https://www.haoranyou.com/castling-vit/)]
  - Linear-Angular Attention to measuring spectral similarity

- [HGFormer]Hierarchical Grouping Transformer for Domain Generalized Semantic Segmentation[[paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_HGFormer_Hierarchical_Grouping_Transformer_for_Domain_Generalized_Semantic_Segmentation_CVPR_2023_paper.pdf), [project](https://github.com/dingjiansw101/HGFormer)]

